#!/bin/bash

#SBATCH --job-name=parsl.auto.1552253091.9394164
#SBATCH --output=/scratch/midway2/tkurihana/parsl/parsl/dataflow/workspace/workjob/app1_grd/runinfo/011/submit_scripts/parsl.auto.1552253091.9394164.submit.stdout
#SBATCH --error=/scratch/midway2/tkurihana/parsl/parsl/dataflow/workspace/workjob/app1_grd/runinfo/011/submit_scripts/parsl.auto.1552253091.9394164.submit.stderr
#SBATCH --nodes=1
#SBATCH --partition=broadwl
#SBATCH --time=720
#SBATCH --ntasks-per-node=1
#SBATCH --exclusive
#SBATCH --mem-per-cpu=16000 

module load Anaconda3/5.0.0.1; source activate parsl-dev

export JOBNAME="parsl.auto.1552253091.9394164"

export CORES=$SLURM_CPUS_ON_NODE
export NODES=$SLURM_JOB_NUM_NODES

echo "Found cores : $CORES"
echo "Found nodes : $NODES"
WORKERCOUNT=1

cat << SLURM_EOF > cmd_$SLURM_JOB_NAME.sh
process_worker_pool.py   -p 100 -c 1 --task_url=tcp://midway2-0325.rcc.local:54986 --result_url=tcp://midway2-0325.rcc.local:54910 --logdir=/scratch/midway2/tkurihana/parsl/parsl/dataflow/workspace/workjob/app1_grd/runinfo/011/midway_htex --block_id=6 --hb_period=1 --hb_threshold=2 
SLURM_EOF
chmod a+x cmd_$SLURM_JOB_NAME.sh

TASKBLOCKS=1

srun --ntasks $TASKBLOCKS -l bash cmd_$SLURM_JOB_NAME.sh

echo "Done"

